{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('fid_list_4.json', 'r') as readfile:\n",
    "    fp_file = json.load(readfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'fanpage_research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = pymongo.MongoClient(\"localhost\", 27017)\n",
    "db = client.fanpage_research\n",
    "db.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jieba.set_dictionary(\"dict.txt.big\")\n",
    "jieba.analyse.set_stop_words(\"data/household_stop_words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextMining:\n",
    "    def __init__(self,keyword_dict_path, all_post_list):\n",
    "        self.keyword_dict_path = keyword_dict_path\n",
    "        self.all_post_list = all_post_list\n",
    "        self.keyword_dict = self.get_keyword_dict()\n",
    "        self.idf_list = self.get_idf_list()\n",
    "    def get_keyword_dict(self):\n",
    "        with open(self.keyword_dict_path,'r') as infile:\n",
    "            keyword_dict = json.load(infile, object_pairs_hook=OrderedDict)\n",
    "        return keyword_dict\n",
    "    def make_tf_vector(self,msg,print_out=False):\n",
    "        tf_vector = []\n",
    "        jieba_list = list(jieba.cut(msg))\n",
    "        for typology in self.keyword_dict:\n",
    "            word_count_list = [jieba_list.count(word) for word in self.keyword_dict[typology]]\n",
    "            tf_vector.append(sum(word_count_list))\n",
    "            if print_out :\n",
    "                match_word = \"\"\n",
    "                for idx, word_count in enumerate(word_count_list):\n",
    "                    if word_count > 0:\n",
    "                        match_word+=self.keyword_dict[typology][idx]+' count '+str(word_count)+','\n",
    "                print \"%s (term count :%d)  %s\" % (typology,sum(word_count_list),match_word)\n",
    "        return tf_vector\n",
    "    def get_idf_list(self,refresh=False):\n",
    "        tf_vector_list = []\n",
    "        for post in self.all_post_list :\n",
    "            tf_vector_list.append(self.make_tf_vector(post))           \n",
    "        feature_vector_list = np.array(tf_vector_list)\n",
    "        num_total_document = feature_vector_list.shape[0]\n",
    "        num_term = feature_vector_list.shape[1]\n",
    "        num_documentIncludeTerm_list = []\n",
    "        for idx in range(num_term):\n",
    "            termCount_document = [v[idx] for v in feature_vector_list]\n",
    "            num_documentIncludeTerm_list.append(num_total_document-termCount_document.count(0))\n",
    "        idf_list = [math.log1p(num_total_document/f) for f in num_documentIncludeTerm_list]\n",
    "        return idf_list\n",
    "    def make_tfidf_vector(self,msg,print_out=False):\n",
    "        tfidf_vector = []\n",
    "        tf_list = self.make_tf_vector(msg,print_out)\n",
    "        for (a,b) in zip(tf_list, self.idf_list):\n",
    "            tfidf_vector.append(a*b)\n",
    "        return tfidf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_predict(feature_vector,print_out=False):\n",
    "    prediction = []\n",
    "    class_dict = {\n",
    "        \"class_0\" : [11,12],\n",
    "        \"class_1\" : [3,4,5,6],\n",
    "        \"class_2\" : [7,8,9,10,13],\n",
    "        \"class_3\" : [0,1,2]}\n",
    "    max_class_sum = float(\"-inf\")\n",
    "    max_class = None\n",
    "    for i in range(len(class_dict)):\n",
    "        class_sum = sum(feature_vector[idx] for idx in class_dict[\"class_\"+str(i)])\n",
    "        if print_out==True:\n",
    "            print 'class %s : %f' % (i,class_sum)\n",
    "        if class_sum >= max_class_sum:\n",
    "            max_class_sum = class_sum\n",
    "            max_class = i\n",
    "    return max_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Brand:\n",
    "    \n",
    "    def __init__(self,fid):\n",
    "        self.fid = fid\n",
    "        self.start_fan_count, self.stop_fan_count = self.get_fan_count()\n",
    "        self.post_count,self.pid_list,self.msg_list = self.get_post_info()\n",
    "        self.certificate = self.get_certificate_status()\n",
    "        self.like_count_list, self.comment_count_list, self.share_count_list, self.tag_count_list = self.get_post_detail()\n",
    "        self.valid_post_count, self.valid_pid_list, self.valid_msg_list = self.get_valid_post()\n",
    "        self.promo_pid_list, self.engage_pid_list, self.product_pid_list, self.brand_pid_list = self.classify_post()\n",
    "    def get_fan_count(self):\n",
    "        \"\"\"\n",
    "        Get fan count from mongoDB.\n",
    "        \n",
    "        :return: fan count in the inital data, fan count in the last data\n",
    "        :rtype: int, int\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cursor = db.fanpage.find({\"fid\":self.fid})\n",
    "            fan_count_list = [document for document in cursor]\n",
    "            if fan_count_list[0]['fan_count']>0 and fan_count_list[-1]['fan_count']>0:\n",
    "                return fan_count_list[0]['fan_count'], fan_count_list[-1]['fan_count']\n",
    "            else:\n",
    "                print \"Get fan_count is zero, pls check\"\n",
    "                return\n",
    "        except:\n",
    "            print \"fail to get fanpage information from mongoDB %s\" % self.fid\n",
    "    \n",
    "    def get_post_info(self):\n",
    "        \"\"\"\n",
    "        Get post count and all pid list from mongoDB exclude posts with \"null\" message.\n",
    "        \n",
    "        :return: count of total posts, all pid\n",
    "        :rtype: int, list\n",
    "        \"\"\"\n",
    "        try:\n",
    "            pid_list = []\n",
    "            msg_list = []\n",
    "            cursor = db.post.aggregate([{\"$match\":{'fid':self.fid, \"message\":{\"$ne\":None}}}])\n",
    "            for document in cursor :     \n",
    "                pid_list.append(document['pid'])\n",
    "                msg_list.append(document['message'])\n",
    "            return len(pid_list), pid_list, msg_list\n",
    "        except:\n",
    "            print \"fail to get post information from mongoDB %s\" % self.fid\n",
    "    \n",
    "    def get_certificate_status(self):\n",
    "        \"\"\"\n",
    "        Get certificate status from outside file :'fid_list_4.json'.\n",
    "        \n",
    "        :return: The certificate status on facebook\n",
    "        :rtype: boolean\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for fp in fp_file:\n",
    "                if self.fid == fp['fid']:\n",
    "                    return False if fp['fb_cert']=='NA' else True\n",
    "        except:\n",
    "            print \"fail to get certificate status from mongoDB %s\" % self.fid\n",
    "\n",
    "    def get_post_detail(self):\n",
    "        \"\"\"\n",
    "        Get post details from mongoDB.\n",
    "        \n",
    "        :return: like count list, comment count list, share count list, friend tagging count list\n",
    "        :rtype: list, list, list, list\n",
    "        \"\"\"\n",
    "        like_count_list = []\n",
    "        comment_count_list = []\n",
    "        share_count_list = []\n",
    "        tag_count_list = []\n",
    "        for pid in self.pid_list:\n",
    "            try:\n",
    "                cursor = db.post_detail.aggregate([{\"$match\":{\"pid\":pid}},\n",
    "                                                   {\"$group\":{\"_id\":\"$pid\",\n",
    "                                                              \"maxLike\":{\"$max\":\"$like_count\"},\n",
    "                                                              \"maxComment\":{\"$max\":\"$comment_count\"},\n",
    "                                                              \"maxShare\":{\"$max\":\"$share_count\"},\n",
    "                                                              \"maxTag\":{\"$max\":\"$friend_tagg_count\"}}}])\n",
    "                cursor_result = [document for document in cursor]\n",
    "                like_count_list.append(cursor_result[0]['maxLike'])\n",
    "                comment_count_list.append(cursor_result[0]['maxComment'])\n",
    "                share_count_list.append(cursor_result[0]['maxShare'])\n",
    "                tag_count_list.append(cursor_result[0]['maxTag'])\n",
    "            except:\n",
    "                print \"fail to get post detail from mongoDB %s\" % pid\n",
    "        return like_count_list,comment_count_list,share_count_list,tag_count_list\n",
    "    \n",
    "    def get_valid_post(self):\n",
    "        valid_pid_list = []\n",
    "        valid_msg_list = []\n",
    "        for like_count, pid, msg in zip(self.like_count_list,self.pid_list,self.msg_list):\n",
    "            valid_pid_list+=[pid] if like_count > 0 else []\n",
    "            valid_msg_list+=[msg] if like_count > 0 else []\n",
    "        return len(valid_pid_list), valid_pid_list, valid_msg_list\n",
    "           \n",
    "    def classify_post(self):\n",
    "        class_result = []\n",
    "        tm = TextMining(\"data/keyword_all_2.json\",self.valid_msg_list)\n",
    "        for pid, msg in zip(self.valid_pid_list, self.valid_msg_list):\n",
    "            class_result.append(tfidf_predict(tm.make_tfidf_vector(msg)))\n",
    "        promo_pid_list = np.array(self.valid_pid_list)[np.array(class_result)==0]\n",
    "        engage_pid_iist = np.array(self.valid_pid_list)[np.array(class_result)==1]\n",
    "        product_pid_list = np.array(self.valid_pid_list)[np.array(class_result)==2]\n",
    "        brand_pid_list = np.array(self.valid_pid_list)[np.array(class_result)==3]\n",
    "        return promo_pid_list, engage_pid_iist, product_pid_list, brand_pid_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_brand = Brand(\"601530866559001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55016 55600\n"
     ]
    }
   ],
   "source": [
    "print test_brand.start_fan_count, test_brand.stop_fan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like_count for each post : [18, 281, 16, 16, 12, 21, 16, 20, 25, 33, 14, 23, 17, 18, 21, 15, 16, 19, 19, 12, 18, 10, 7, 8, 2766, 6, 8, 21, 582, 11, 8639, 9, 19, 20, 14, 11, 27, 20, 83, 16, 26, 11, 11, 14, 0, 0, 0, 0, 10, 13, 9, 395, 0, 0, 0, 0, 0]\n",
      "comment_count for each post : [3, 270, 3, 3, 2, 3, 7, 3, 3, 3, 2, 5, 5, 3, 5, 3, 3, 3, 3, 3, 3, 3, 2, 2, 9, 2, 3, 2, 568, 2, 127, 2, 4, 3, 3, 2, 3, 6, 63, 2, 2, 2, 2, 3, 0, 0, 0, 0, 2, 3, 2, 375, 0, 0, 0, 0, 0]\n",
      "share_count for each post : [0, 213, 1, 2, 2, 0, 0, 1, 4, 2, 1, 1, 2, 2, 1, 0, 1, 4, 2, 2, 2, 1, 0, 0, 11, 2, 2, 3, 541, 5, 135, 3, 1, 2, 3, 1, 3, 3, 59, 1, 2, 2, 2, 1, 0, 0, 0, 0, 0, 6, 1, 225, 0, 0, 0, 0, 0]\n",
      "friendTagging_count for each post : [0, 170, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 230, 0, 37, 0, 0, 0, 0, 0, 0, 0, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 293, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print \"like_count for each post :\", test_brand.like_count_list\n",
    "print \"comment_count for each post :\", test_brand.comment_count_list\n",
    "print \"share_count for each post :\", test_brand.share_count_list\n",
    "print \"friendTagging_count for each post :\", test_brand.tag_count_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
