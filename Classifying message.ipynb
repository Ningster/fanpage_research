{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#0 : Promotional  5.33% 折扣、下殺 特價。。。\n",
    "#1: Engagement  31.56%   按讚、打卡 分享。。。\n",
    "#2: Product Awareness  28% (產品) “new product” 系列、首發、新登場、開箱、推薦 新一代 進化版\n",
    "#3: Brand Awareness 8.44%（品牌）\n",
    "#Corporate Social Responsibility 5.33%\n",
    "#Customer Service 3.11% (粉絲) 服務 品管\n",
    "#Seasonal 18.67%     開學、情人節\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "import os.path\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "db = client['fanpage_research']\n",
    "coll_fanpage = db['fanpage']\n",
    "coll_post = db['post']\n",
    "coll_post_detail = db['post_detail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('fid_list_4.json') as d:\n",
    "    all_fid_list = json.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "jieba.set_dictionary(\"dict.txt.big\")\n",
    "stop_words_path = \"data/household_stop_words.txt\"\n",
    "jieba.analyse.set_stop_words(stop_words_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pp(o):\n",
    "    print json.dumps(o,indent=1,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_combined_message_by_label(X_array, y_array, label):\n",
    "    nd_X = np.array(X_array)\n",
    "    nd_y = np.array(y_array)\n",
    "    words = \"\"\n",
    "    for p in nd_X[nd_y==label]:\n",
    "        if p['message'] is not None:\n",
    "            words = words + p['message']\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_keyword(X_array, y_array, label):\n",
    "    combined_message = get_combined_message_by_label(X_array, y_array, label)\n",
    "    return jieba.analyse.extract_tags(combined_message, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### -----------------above functions are global functions----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class industry_data:\n",
    "    def __init__(self,industry_name_list,all_fid_list):\n",
    "        self.name_list = industry_name_list\n",
    "        self.name_abbr = None\n",
    "        self.all_fid_list = all_fid_list\n",
    "        self.fid_list = None\n",
    "        self.posts = None\n",
    "        self.train_post = None\n",
    "        self.train_label = None\n",
    "        self.test_post = None\n",
    "        self.test_label = None\n",
    "    def get_name(self):\n",
    "        name = \"\"\n",
    "        if self.name_abbr == None:\n",
    "            for i in self.name_list:\n",
    "                name = name + i.rsplit(' ')[0]\n",
    "            self.name_abbr = name\n",
    "        return self.name_abbr\n",
    "    def get_fid_list(self,refresh=False):\n",
    "        if self.fid_list == None or refresh == True:\n",
    "            fid_list = []\n",
    "            for f in self.all_fid_list:\n",
    "                if f['category'] in self.name_list:\n",
    "                    fid_list.append(f['fid'])\n",
    "            self.fid_list = fid_list\n",
    "        return self.fid_list\n",
    "    def get_posts(self,refresh=False):\n",
    "        fid_list = self.get_fid_list()\n",
    "        if self.posts == None or refresh == True:\n",
    "            posts = []\n",
    "            for f in fid_list:\n",
    "                posts = posts + [p for p in coll_post.find({\"fid\":f},{'date':False,'_id':False})]\n",
    "            self.posts = posts\n",
    "        return self.posts\n",
    "    def get_train_post_label(self,sample_number=50,refresh=False):\n",
    "        self.train_label == None\n",
    "        if self.train_post == None or self.train_label == None or refresh == True:\n",
    "            file_name = 'data/train_data_'+self.get_name()+'.json'\n",
    "            if refresh == True or (not os.path.isfile(file_name)):\n",
    "                tmp_dict = {} \n",
    "                posts = self.get_posts()\n",
    "                tmp_dict['train_X'] = [p for p in np.random.choice(posts, 50, replace=False)]\n",
    "                tmp_dict['train_y'] = []\n",
    "                with open(file_name,'w') as outfile:\n",
    "                    json.dump(tmp_dict,outfile)\n",
    "            with open(file_name,'r') as infile:\n",
    "                j_file = json.load(infile)\n",
    "            try:\n",
    "                self.train_post = j_file['train_X']\n",
    "                self.train_label = j_file['train_y']\n",
    "            except:\n",
    "                print \"error occured when accessing\"+file_name+\"[train_X] or [train_y]\"          \n",
    "        return self.train_post,self.train_label\n",
    "    def get_test_post_label(self, sample_number = 50, refresh=False):\n",
    "        self.test_label == None\n",
    "        if self.test_post == None or self.test_label == None or refresh == True:\n",
    "            file_name = 'data/test_data_'+self.get_name()+'.json'\n",
    "            if refresh == True or (not os.path.isfile(file_name)):\n",
    "                tmp_dict = {} \n",
    "                train_X, train_y = self.get_train_post_label()\n",
    "                all_posts = self.get_posts()\n",
    "                posts_without_trainX = [i for i in all_posts if i not in train_X]\n",
    "                tmp_dict['test_X'] = [p for p in np.random.choice(posts_without_trainX, 50, replace=False)]\n",
    "                tmp_dict['test_y'] = []\n",
    "                with open(file_name,'w') as outfile:\n",
    "                    json.dump(tmp_dict,outfile)\n",
    "            with open(file_name,'r') as infile:\n",
    "                j_file = json.load(infile)\n",
    "            try:\n",
    "                self.test_post = j_file['test_X']\n",
    "                self.test_label = j_file['test_y']\n",
    "            except:\n",
    "                print \"error occured when accessing\"+file_name+\"[test_X] or [test_y]\"          \n",
    "        return self.test_post,self.test_label    \n",
    "    def get_keyword_category(self):\n",
    "        X, y = self.get_train_post_label()\n",
    "        keyword_dict = collections.OrderedDict()\n",
    "        if len(X)==len(y) and len(X)!=0:\n",
    "            for i in range(4):\n",
    "                combined_message = get_combined_message_by_label(X, y, i)\n",
    "                keyword_dict['class_'+str(i)] = jieba.analyse.extract_tags(combined_message, 10)\n",
    "        return keyword_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self,industry):\n",
    "        self.name = industry\n",
    "        self.keyword_dict = None\n",
    "    def get_keyword_dict(self,refresh=False):\n",
    "        if self.keyword_dict == None or refresh == True:\n",
    "            file_name = 'data/keyword_'+self.name+'.json'\n",
    "            if os.path.isfile(file_name):\n",
    "                with open(file_name,'r') as infile:\n",
    "                    keyword_file = collections.OrderedDict(json.load(infile))\n",
    "                self.keyword_dict = keyword_file\n",
    "            else:\n",
    "                print file_name+\" doesn't exist\"\n",
    "                return \n",
    "        return self.keyword_dict\n",
    "    \n",
    "# Below is stupid model\n",
    "#     def _predict(self,message):\n",
    "#         message_jieba = jieba.analyse.extract_tags(message,0)\n",
    "#         key_dict = self.get_keyword_dict()\n",
    "        \n",
    "#         print 'message jieba : ',','.join(message_jieba)\n",
    "#         print 'keyword 0',','.join(key_dict['class_0'])\n",
    "#         print 'keyword 1 : ',','.join(key_dict['class_1'])\n",
    "#         print 'keyword 2',','.join(key_dict['class_2'])\n",
    "        \n",
    "#         match_class_0 = list(set(message_jieba).intersection(key_dict['class_0']))\n",
    "#         match_class_1 = list(set(message_jieba).intersection(key_dict['class_1']))\n",
    "#         match_class_2 = list(set(message_jieba).intersection(key_dict['class_2']))\n",
    "\n",
    "#         print \"0: \", ','.join(match_class_0)\n",
    "#         print \"1: \", ','.join(match_class_1)\n",
    "#         print \"2: \", ','.join(match_class_2)\n",
    "#         if len(match_class_1)>0:\n",
    "#             if len(match_class_1)==1 and u'分享' in match_class_1:\n",
    "#                 if u'粉絲' in message_jieba:   #粉絲＋分享 --> 1\n",
    "#                     return 1\n",
    "#                 else:\n",
    "#                     if len(match_class_0)>0:  #分享＋送好禮-->1\n",
    "#                         return 1                    \n",
    "#                     return 3\n",
    "#             return 1\n",
    "#         elif len(match_class_0)>0:\n",
    "#             return 0\n",
    "#         elif len(match_class_2)>0:\n",
    "#             return 2\n",
    "#         else:\n",
    "#             return 3\n",
    "#     def predict(self,data_set):\n",
    "#         pre_y = []\n",
    "#         predict_class = None\n",
    "#         for d in data_set:\n",
    "#             if d['message']!=None:\n",
    "#                 pre_y.append(self._predict(d['message']))\n",
    "#                 predict_class = self._predict(d['message'])\n",
    "#             else:\n",
    "#                 if d['post_type'] in ['album','photo','cover_photo','video','video_inline','image_share','animated_image_share','video_direct_response']:\n",
    "#                     pre_y.append(1)\n",
    "#                     predict_class = 1\n",
    "#                 else:\n",
    "#                     pre_y.append(3)\n",
    "#                     predict_class = 3\n",
    "#             print predict_class\n",
    "#             print d\n",
    "#             print '---------------------------'\n",
    "#         return pre_y\n",
    "#Above is stupid model\n",
    "\n",
    "    def _make_ML_X(self,input_X,print_out=False):\n",
    "        key_dict = self.get_keyword_dict()\n",
    "        ML_X = []\n",
    "        for obj in input_X:\n",
    "            tmp = []\n",
    "            has_vivid = 0\n",
    "            if obj['post_type'] in ['album','photo','cover_photo','video','video_inline','image_share','animated_image_share','video_direct_response']:\n",
    "                has_vivid = 1\n",
    "            match = []\n",
    "            obj_message = obj['message']\n",
    "            for k in key_dict:\n",
    "                if obj_message!=None:\n",
    "                    message_jieba = jieba.analyse.extract_tags(obj['message'],0)\n",
    "                    match = list(set(message_jieba).intersection(key_dict[k]))\n",
    "                if print_out:\n",
    "                    print 'match '+k+' : ',','.join(match)\n",
    "                tmp.append(len(match))\n",
    "            tmp.append(has_vivid)\n",
    "            ML_X.append(tmp)\n",
    "        return ML_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Machine Learning Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1700,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ML:\n",
    "    # industry_name is a list obj\n",
    "    def __init__(self,industry_name_list):\n",
    "        self.industry_obj = industry_data(industry_name_list,all_fid_list)\n",
    "        self.train_X, self.train_y = self.industry_obj.get_train_post_label()\n",
    "        self.test_X, self.test_y = self.industry_obj.get_test_post_label()\n",
    "        self.classifier = Classifier(self.industry_obj.name_abbr)\n",
    "        self.ML_train_X = self.classifier._make_ML_X(self.train_X)\n",
    "        self.ML_test_X = self.classifier._make_ML_X(self.test_X)\n",
    "        self.model_lg = None\n",
    "        self.model_tree = None\n",
    "    def get_model_tree(self,refresh=False):\n",
    "        if self.model_tree == None or refresh == True:\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "            clf_model = clf.fit(np.array(self.ML_train_X),np.array(self.train_y))\n",
    "            self.model_tree = clf_model\n",
    "        return self.model_tree\n",
    "    def get_model_lg(self,refresh=False):\n",
    "        if self.model_lg == None or refresh == True:\n",
    "            lg = LogisticRegression()\n",
    "            lg_model = lg.fit(np.array(self.ML_train_X),np.array(self.train_y))\n",
    "            self.model_lg = lg_model\n",
    "        return self.model_lg\n",
    "    def _predict(self,ML_X,model='lg'):\n",
    "        prediction = None\n",
    "        if model == \"lg\":\n",
    "            prediction = self.get_model_lg().predict(np.array(ML_X))\n",
    "        elif model == \"tree\":\n",
    "            prediction = self.get_model_tree().predict(np.array(ML_X))\n",
    "        return prediction\n",
    "    def accuracy(self,ML_X,y,model = 'lg'):\n",
    "        prediction = self._predict(ML_X,model)\n",
    "        accuracy = np.mean(prediction==np.array(y))\n",
    "        correct_idx = np.where(prediction==np.array(y))[0]\n",
    "        incorrect_idx = np.where(prediction!=np.array(y))[0]\n",
    "        print \"accuracy:\",accuracy\n",
    "        print \"correct_idx:\",correct_idx\n",
    "        print \"incorrect_idx:\",incorrect_idx \n",
    "    def checkOne(self,X,y,index,model='lg'):\n",
    "        ML_X = self.classifier._make_ML_X([X[index]],print_out = True)\n",
    "        print \"predict class : \", self._predict(np.reshape(np.array(ML_X),(1,-1)),model)\n",
    "        print \"true class : \", y[index]\n",
    "        print X[index]['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.84\n",
      "correct_idx: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 22 23 24 25 26 27\n",
      " 28 29 30 31 32 34 35 36 37 38 39 40 41 42 43 47 48]\n",
      "incorrect_idx: [ 2 20 21 33 44 45 46 49]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "retail_ML = ML(['retail'])\n",
    "print retail_ML.accuracy(retail_ML.ML_test_X, retail_ML.test_y,\"lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1729,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match class_2 :  產品\n",
      "match class_3 :  \n",
      "match class_0 :  \n",
      "match class_1 :  \n",
      "predict class :  [2]\n",
      "true class :  3\n",
      "CITIZEN Watch Group展示廳\n",
      "\n",
      "今年BASELWORLD的CITIZEN展場當中\n",
      "有另一個亮點！－CITIZEN Watch Group的展示廳。\n",
      "\n",
      "在這我們聚集\n",
      "CITIZEN Watch Group現在所擁有的手錶品牌 ：\n",
      "Alpina、Arnold & Son、BULOVA、\n",
      "CAMPANOLA 、CITIZEN 以及 Ferderiue Constant .\n",
      "\n",
      "在這廣大的空間内展示各品牌的最新產品，\n",
      "不僅便於展現各自獨特的美學理念，\n",
      "也能更好的與大眾溝通CITIZEN Watch Group的美好願景。\n",
      "\n",
      "〉BASELWORLD 2017\n",
      " http://www.citizenwatch.com.tw/event2017/baselworld/index.html\n"
     ]
    }
   ],
   "source": [
    "retail_ML.checkOne(retail_ML.test_X,retail_ML.test_y,2,\"lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1734,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.96\n",
      "correct_idx: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "incorrect_idx: [ 7 49]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "house_ML = ML(['Household & Personal Care'])\n",
    "print house_ML.accuracy(house_ML.ML_test_X, house_ML.test_y,\"lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1737,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match class_2 :  試用\n",
      "match class_3 :  活動\n",
      "match class_0 :  得獎,好禮,優惠,得獎者\n",
      "match class_1 :  加入\n",
      "predict class :  [0]\n",
      "true class :  1\n",
      "【好奇寶寶聚樂部 「迎新入會尿布免費抽」- 🎉得獎名單🎉出爐囉！！】\n",
      "\n",
      "歡迎新加入的媽咪們❤更恭喜這個月抽到✨五箱紫好奇✨的幸運兒，讓人好生羨慕啊😍😍😍~~。你也想把五箱紫好奇搬回家嗎？活動於4/30截止，還沒加入會員的媽咪們快來加入「好奇寶寶聚樂部」吧！\n",
      "心動不如馬上行動🎁 立即加入好奇寶寶聚樂部: https://goo.gl/bhmiGO\n",
      "\n",
      "專屬好奇寶寶聚樂部會員四大好禮: \n",
      "👏得到各項通路與產品的優惠資訊\n",
      "👏新生寶寶專屬禮\n",
      "👏產品試用包\n",
      "👏孕期/育兒新知電子報\n",
      "\n",
      "🎉 得獎者們記得在3/24(五)前主動聯絡我們唷，請來電0800-221-526或mail聯絡資訊至customerservice.0800@kcc.com！ \n",
      "聯絡資訊請提供Facebook姓名及登入用之Email、真實姓名、電話、收件地址，將由專人協助領獎。\n",
      "得獎者恕不另行通知，逾期回覆將視同棄權，如有任何問題請於上班時間(週一至週五 09:00-12:00 / 13:30-17:00)洽詢好奇客服專線 0800-221 -526。\n"
     ]
    }
   ],
   "source": [
    "house_ML.checkOne(house_ML.test_X,house_ML.test_y,7,\"lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Household + Retail & 不分keyword list (keyword_all.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1815,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9\n",
      "correct_idx: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 27 28 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n",
      " 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 72 73 74 75 76 77 79 80\n",
      " 81 82 83 84 85 86 87 88 89 90 91 92 93 97 98]\n",
      "incorrect_idx: [26 29 52 70 71 78 94 95 96 99]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "RetailHouse = ML(['Retail','Household & Personal Care'])\n",
    "print RetailHouse.accuracy(RetailHouse.ML_test_X, RetailHouse.test_y,\"lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1829,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match product_test :  \n",
      "match product_new :  \n",
      "match info_event :  \n",
      "match monetary_incentive :  \n",
      "match product_unit :  \n",
      "match price_off :  75折\n",
      "match engage_other :  \n",
      "match product_version :  \n",
      "match info_brand :  \n",
      "match push_word :  \n",
      "match engage_join :  \n",
      "match engage_interaction :  \n",
      "predict class :  [2]\n",
      "true class :  2\n",
      "💢明明很累卻睡不著\n",
      "今晚又要失眠了嗎？😵\n",
      "別沮喪！試試這招↓↓\n",
      "💤睡前用晚安舒眠噴霧\n",
      "對著枕頭、棉被、臥室\n",
      "咻！咻！噴個幾下\n",
      "馬上散發甜橙和薰衣草香氛🍊\n",
      "整個人變得好放鬆\n",
      "今晚一定好好睡！\n",
      "\n",
      "晚安舒眠噴霧2瓶組↘75折\n",
      "https://goo.gl/QanGwx\n",
      "\n",
      "轉載自華人健康網\n",
      "\n",
      " — Products shown: 晚安舒眠噴霧2瓶組.\n"
     ]
    }
   ],
   "source": [
    "RetailHouse.checkOne(RetailHouse.test_X,RetailHouse.test_y,2,\"lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1830,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 19, 36, 29])"
      ]
     },
     "execution_count": 1830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(RetailHouse.train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
